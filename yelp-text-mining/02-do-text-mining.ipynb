{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4842f8e7-7aa5-4878-b31e-eb3fe298c203",
   "metadata": {},
   "source": [
    "# Text Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42261544-9cf9-459b-9c7a-2e7ad7929c59",
   "metadata": {},
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb745d3b-688a-40db-9e14-b93ca2162d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages to use later\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c151a2-e67f-45f4-8bed-de4ad750a63d",
   "metadata": {},
   "source": [
    "## Load & Process Relationship Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "496706e8-2533-4890-a420-c7756a0a5e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['child,children,kid,kids', 'daughter,daughters', 'son,sons', 'parent,parents', 'mother,mom', 'father,dad', 'brother,brothers', 'sister,sisters', 'siblings', 'aunt,aunts', 'uncle,uncles', 'niece,nieces', 'nephew,nephews', 'cousin,cousins', 'grandchild,grandchildren', 'grandmother,grandma', 'grandfather,grandpa', 'grandparents', 'spouse', 'partner', 'husband', 'wife', 'bff', 'relationship', 'date', 'boo,bae,sweetheart', 'fiancee,fiance', 'girlfriend,gf', 'boyfriend,bf', 'friend,friends,buddy,buddies,pal,pals', 'housemate,housemates,roommate,roommates,flatmate,flatmates', 'neighbor,neighbors', 'classmate,classmates', 'professor,professors', 'teacher,teachers', 'coworker,coworkers,colleague,colleagues', 'client,clients', 'boss']\n",
      "{'my_clients', 'my_grandpa', 'my_nephew', 'my_daughter', 'my_siblings', 'my_brothers', 'my_dad', 'my_flatmates', 'my_pals', 'my_classmate', 'my_boyfriend', 'my_professors', 'my_colleague', 'my_sweetheart', 'my_mother', 'my_sister', 'my_coworkers', 'my_cousins', 'my_coworker', 'my_friend', 'my_brother', 'my_relationship', 'our_kids', 'my_roommate', 'my_children', 'my_father', 'my_neighbors', 'my_fiancee', 'my_aunts', 'our_son', 'my_roommates', 'my_spouse', 'my_professor', 'our_daughters', 'my_girlfriend', 'my_boss', 'my_bae', 'my_grandmother', 'my_cousin', 'my_niece', 'our_child', 'my_parent', 'my_classmates', 'my_housemate', 'my_fiance', 'our_sons', 'my_colleagues', 'my_grandma', 'my_bff', 'our_daughter', 'my_grandchildren', 'my_uncles', 'my_daughters', 'my_flatmate', 'my_date', 'my_friends', 'my_teachers', 'my_grandfather', 'my_aunt', 'my_bf', 'my_pal', 'my_grandparents', 'my_kid', 'my_buddy', 'our_kid', 'my_wife', 'my_uncle', 'my_nephews', 'my_husband', 'my_kids', 'my_mom', 'my_client', 'my_boo', 'our_children', 'my_housemates', 'my_child', 'my_son', 'my_nieces', 'my_grandchild', 'my_parents', 'my_sons', 'my_neighbor', 'my_sisters', 'my_teacher', 'my_partner', 'my_buddies', 'my_gf'}\n"
     ]
    }
   ],
   "source": [
    "# Why should we set up the relationships data like this?\n",
    "# 1) Prevents need for stemming each word in each review (time-consuming)\n",
    "# 2) Allows arbitrary groupings of relationships beyond stemming equivalence\n",
    "#    (e.g. \"roommate\" and \"housemate\", \"children\" and \"kids\", etc.)\n",
    "\n",
    "with open(\"relationships/Relationships_ATUS_custom_v2.txt\") as f:\n",
    "    relationships = [line.strip().lower() for line in f.readlines()]\n",
    "\n",
    "relationships_dict = dict()  ## From relationship category to all relevant relationship words, e.g. \"spouse\" --> [\"spouse\", \"partner\"]\n",
    "relationships_dict_reverse = dict()  ## From any relationship word to its category, e.g. \"partner\" --> \"spouse\"\n",
    "\n",
    "for line in relationships:\n",
    "    relevant_words = line.split(\",\")\n",
    "    category = relevant_words[0]\n",
    "    relationships_dict[category] = relevant_words.copy()\n",
    "    for word in relevant_words:\n",
    "        relationships_dict_reverse[word] = category\n",
    "\n",
    "full_relationship_set = set()\n",
    "for relationship_list in relationships_dict.values():\n",
    "    full_relationship_set.update(relationship_list)\n",
    "        \n",
    "print(relationships)\n",
    "#print()\n",
    "#print(relationships_dict)\n",
    "#print()\n",
    "#print(relationships_dict_reverse)\n",
    "\n",
    "words_need_our = [\"child\", \"children\", \"kid\", \"kids\", \"son\", \"sons\", \"daughter\", \"daughters\"]\n",
    "\n",
    "full_relationship_set_new = set()\n",
    "for word in full_relationship_set:\n",
    "    full_relationship_set_new.add(\"my_\" + word)\n",
    "    if word in words_need_our:\n",
    "        full_relationship_set_new.add(\"our_\" + word)\n",
    "print(full_relationship_set_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709f0557-bdf0-4157-a114-103d81e54f29",
   "metadata": {},
   "source": [
    "## Text Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ccfe00f-583f-4c30-8f76-a4cae42e8f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>funny</th>\n",
       "      <th>useful</th>\n",
       "      <th>review_id</th>\n",
       "      <th>text</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>date</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>elqRpX9T3YwL07uLNtN3Bg</td>\n",
       "      <td>I at least have to give this restaurant two st...</td>\n",
       "      <td>ltBBYdNzkeKdCNPDAsxwAA</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2015-02-02 04:29:13</td>\n",
       "      <td>-sryo4gDYxbZ1T5Bz4l5Bw</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-02-02 04:29:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>p198qZsKOMCUhgdtRWsOKQ</td>\n",
       "      <td>After my ROTD  yesterday of a different Sweet ...</td>\n",
       "      <td>8QnuWGVNBhzyYXGSeRdi4g</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2013-10-24 19:24:33</td>\n",
       "      <td>3MpDvy5gEdsbZh9-p92dHg</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-10-24 19:24:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>E9AB7V4z8xrt2uPF7T55FQ</td>\n",
       "      <td>Amazing biscuits and (fill in the blank). Grea...</td>\n",
       "      <td>Zx7n8mdt8OzLRXVzolXNhQ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2018-04-27 23:03:21</td>\n",
       "      <td>iYY5Ii1LGpZCpXFkHlMefw</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-27 23:03:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  funny  useful               review_id  \\\n",
       "0          29      0       0  elqRpX9T3YwL07uLNtN3Bg   \n",
       "1          34      0       0  p198qZsKOMCUhgdtRWsOKQ   \n",
       "2          39      0       0  E9AB7V4z8xrt2uPF7T55FQ   \n",
       "\n",
       "                                                text             business_id  \\\n",
       "0  I at least have to give this restaurant two st...  ltBBYdNzkeKdCNPDAsxwAA   \n",
       "1  After my ROTD  yesterday of a different Sweet ...  8QnuWGVNBhzyYXGSeRdi4g   \n",
       "2  Amazing biscuits and (fill in the blank). Grea...  Zx7n8mdt8OzLRXVzolXNhQ   \n",
       "\n",
       "   stars                 date                 user_id  cool  \\\n",
       "0    2.0  2015-02-02 04:29:13  -sryo4gDYxbZ1T5Bz4l5Bw     0   \n",
       "1    4.0  2013-10-24 19:24:33  3MpDvy5gEdsbZh9-p92dHg     0   \n",
       "2    5.0  2018-04-27 23:03:21  iYY5Ii1LGpZCpXFkHlMefw     0   \n",
       "\n",
       "              datetime  \n",
       "0  2015-02-02 04:29:13  \n",
       "1  2013-10-24 19:24:33  \n",
       "2  2018-04-27 23:03:21  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metros = ['Indianapolis', 'Philadelphia', 'Tucson', 'Tampa', 'Nashville']\n",
    "\n",
    "metro = 'Nashville'\n",
    "# metro_reviews = pd.read_csv(\"small_reviews/yelp_academic_dataset_reviews_\" + metro + \".csv\")\n",
    "metro_reviews = pd.read_csv(\"small_reviews_urbcomp/yelp_academic_dataset_reviews_\" + metro + \".csv\")\n",
    "metro_reviews.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "354d2a4b-55f2-4ef2-a409-a7ae9f62017c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.083009004592896 sec\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "# Clean review text by making everything lowercase\n",
    "metro_reviews[\"text_clean\"] = metro_reviews[\"text\"].str.lower()\n",
    "\n",
    "metro_reviews[\"text_clean\"] = metro_reviews[\"text_clean\"].str.replace(\"my \", \"my_\")\n",
    "metro_reviews[\"text_clean\"] = metro_reviews[\"text_clean\"].str.replace(\"our \", \"our_\")\n",
    "\n",
    "#print(metro_reviews[metro_reviews[\"review_id\"] == \"k9vlSSUStwY2DcjM8Rinnw\"].iloc[0, -1])\n",
    "\n",
    "# Apply tokenizer and get rid of punctuation\n",
    "tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "metro_reviews[\"text_clean\"] = metro_reviews[\"text_clean\"].fillna(\"0\")\n",
    "metro_reviews[\"text_clean\"] = metro_reviews[\"text_clean\"].apply(tokenizer.tokenize)\n",
    "\n",
    "# Remove duplicate words in each review\n",
    "metro_reviews[\"text_clean\"] = metro_reviews[\"text_clean\"].apply(set)\n",
    "\n",
    "# Join tokens with spaces into strings for easy word counting\n",
    "metro_reviews[\"text_clean\"] = metro_reviews[\"text_clean\"].apply(\" \".join)\n",
    "\n",
    "t1 = time.time()\n",
    "print(t1-t0, \"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "721ad0a3-f7eb-467b-8321-aab814100df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>funny</th>\n",
       "      <th>useful</th>\n",
       "      <th>review_id</th>\n",
       "      <th>text</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>date</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>datetime</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>elqRpX9T3YwL07uLNtN3Bg</td>\n",
       "      <td>I at least have to give this restaurant two st...</td>\n",
       "      <td>ltBBYdNzkeKdCNPDAsxwAA</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2015-02-02 04:29:13</td>\n",
       "      <td>-sryo4gDYxbZ1T5Bz4l5Bw</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-02-02 04:29:13</td>\n",
       "      <td>had it see she and this restaurant dinner afte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>p198qZsKOMCUhgdtRWsOKQ</td>\n",
       "      <td>After my ROTD  yesterday of a different Sweet ...</td>\n",
       "      <td>8QnuWGVNBhzyYXGSeRdi4g</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2013-10-24 19:24:33</td>\n",
       "      <td>3MpDvy5gEdsbZh9-p92dHg</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-10-24 19:24:33</td>\n",
       "      <td>had it my_rotd and toppings paying my_local af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>E9AB7V4z8xrt2uPF7T55FQ</td>\n",
       "      <td>Amazing biscuits and (fill in the blank). Grea...</td>\n",
       "      <td>Zx7n8mdt8OzLRXVzolXNhQ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2018-04-27 23:03:21</td>\n",
       "      <td>iYY5Ii1LGpZCpXFkHlMefw</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-27 23:03:21</td>\n",
       "      <td>bit cocktails too biscuits amazing and highly ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  funny  useful               review_id  \\\n",
       "0          29      0       0  elqRpX9T3YwL07uLNtN3Bg   \n",
       "1          34      0       0  p198qZsKOMCUhgdtRWsOKQ   \n",
       "2          39      0       0  E9AB7V4z8xrt2uPF7T55FQ   \n",
       "\n",
       "                                                text             business_id  \\\n",
       "0  I at least have to give this restaurant two st...  ltBBYdNzkeKdCNPDAsxwAA   \n",
       "1  After my ROTD  yesterday of a different Sweet ...  8QnuWGVNBhzyYXGSeRdi4g   \n",
       "2  Amazing biscuits and (fill in the blank). Grea...  Zx7n8mdt8OzLRXVzolXNhQ   \n",
       "\n",
       "   stars                 date                 user_id  cool  \\\n",
       "0    2.0  2015-02-02 04:29:13  -sryo4gDYxbZ1T5Bz4l5Bw     0   \n",
       "1    4.0  2013-10-24 19:24:33  3MpDvy5gEdsbZh9-p92dHg     0   \n",
       "2    5.0  2018-04-27 23:03:21  iYY5Ii1LGpZCpXFkHlMefw     0   \n",
       "\n",
       "              datetime                                         text_clean  \n",
       "0  2015-02-02 04:29:13  had it see she and this restaurant dinner afte...  \n",
       "1  2013-10-24 19:24:33  had it my_rotd and toppings paying my_local af...  \n",
       "2  2018-04-27 23:03:21  bit cocktails too biscuits amazing and highly ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metro_reviews.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9840c6d1-081b-4fb3-8c56-525259962066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.14146780967712 sec\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "relationship_categories = sorted(relationships_dict.keys())\n",
    "relationship_categories_ungroup = sorted(relationships_dict_reverse.keys())\n",
    "\n",
    "df_rows = []\n",
    "df_rows_ungroup = []\n",
    "\n",
    "for i, business_id in enumerate(metro_reviews.business_id.unique()):\n",
    "    reviews_subset = metro_reviews[metro_reviews[\"business_id\"] == business_id]\n",
    "    reviews_subset_counts = reviews_subset.text_clean.str.split().explode().value_counts().reset_index()\n",
    "    x = reviews_subset_counts[reviews_subset_counts[\"index\"].isin(full_relationship_set_new)]\n",
    "#     print(x)\n",
    "#     break\n",
    "    df_row = [business_id, len(reviews_subset)] + [0 for key in relationship_categories]\n",
    "    df_row_ungroup = [business_id, len(reviews_subset)] + [0 for key in relationship_categories_ungroup]\n",
    "\n",
    "    for row in x.itertuples():\n",
    "        key = row.index.split(\"_\")[-1]\n",
    "        \n",
    "        df_row_idx = 2 + relationship_categories.index(relationships_dict_reverse[key])\n",
    "        df_row[df_row_idx] += row.text_clean\n",
    "        \n",
    "        df_row_idx_ungroup = 2 + relationship_categories_ungroup.index(key)\n",
    "        df_row_ungroup[df_row_idx_ungroup] += row.text_clean\n",
    "        \n",
    "    df_rows.append(df_row)\n",
    "    df_rows_ungroup.append(df_row_ungroup)\n",
    "\n",
    "relationship_df = pd.DataFrame(df_rows,columns = [\"business_id\", \"num_reviews\"] + relationship_categories)\n",
    "relationship_df['num_relationship_words'] = relationship_df[relationship_categories].sum(axis=1)\n",
    "relationship_df = relationship_df[[\"business_id\", \"num_reviews\", \"num_relationship_words\"] + relationship_categories]\n",
    "\n",
    "relationship_df_ungroup = pd.DataFrame(df_rows_ungroup,columns = [\"business_id\", \"num_reviews\"] + relationship_categories_ungroup)\n",
    "relationship_df_ungroup['num_relationship_words'] = relationship_df_ungroup[relationship_categories_ungroup].sum(axis=1)\n",
    "relationship_df_ungroup = relationship_df_ungroup[[\"business_id\", \"num_reviews\", \"num_relationship_words\"] + relationship_categories_ungroup]\n",
    "\n",
    "t1 = time.time()\n",
    "print(t1-t0, \"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d8c5d18-7e8b-4fd9-b640-0f27cf4916fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "relationship_df.to_csv(\"output_urbcomp/\" + metro + \"_counts_v2.csv\", index=False)\n",
    "relationship_df_ungroup.to_csv(\"output_urbcomp/\" + metro + \"_counts_ungrouped_v2.csv\", index=False)\n",
    "# relationship_df.to_csv(\"output/\" + metro + \"_counts_v2.csv\", index=False)\n",
    "# relationship_df_ungroup.to_csv(\"output/\" + metro + \"_counts_ungrouped_v2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738c8fea-883e-415a-b739-aa279a6523ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
